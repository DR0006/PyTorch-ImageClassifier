{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from PIL import Image\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.rcParams['font.family'] = 'Microsoft YaHei'\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.images = os.listdir(root_dir)\n",
    "        self.labels = [0 if 'cat' in img else 1 for img in self.images]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.images[idx])\n",
    "        image = Image.open(img_name).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# 设置数据集路径\n",
    "dataset_path = '../cc'\n",
    "\n",
    "# 数据预处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 加载图像\n",
    "dataset = CustomDataset(root_dir=dataset_path, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size:2240 and test_size:560\n"
     ]
    },
    {
     "data": {
      "text/plain": "224"
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 划分训练集和测试集\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "print(\"train_size:{} and test_size:{}\".format(train_size, test_size))\n",
    "len(train_dataset[0][0][0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "data": {
      "text/plain": "(70, 18)"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建 DataLoader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "len(train_dataloader), len(test_dataloader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次 1/70, 提取特征中...\n",
      "批次 2/70, 提取特征中...\n",
      "批次 3/70, 提取特征中...\n",
      "批次 4/70, 提取特征中...\n",
      "批次 5/70, 提取特征中...\n",
      "批次 6/70, 提取特征中...\n",
      "批次 7/70, 提取特征中...\n",
      "批次 8/70, 提取特征中...\n",
      "批次 9/70, 提取特征中...\n",
      "批次 10/70, 提取特征中...\n",
      "批次 11/70, 提取特征中...\n",
      "批次 12/70, 提取特征中...\n",
      "批次 13/70, 提取特征中...\n",
      "批次 14/70, 提取特征中...\n",
      "批次 15/70, 提取特征中...\n",
      "批次 16/70, 提取特征中...\n",
      "批次 17/70, 提取特征中...\n",
      "批次 18/70, 提取特征中...\n",
      "批次 19/70, 提取特征中...\n",
      "批次 20/70, 提取特征中...\n",
      "批次 21/70, 提取特征中...\n",
      "批次 22/70, 提取特征中...\n",
      "批次 23/70, 提取特征中...\n",
      "批次 24/70, 提取特征中...\n",
      "批次 25/70, 提取特征中...\n",
      "批次 26/70, 提取特征中...\n",
      "批次 27/70, 提取特征中...\n",
      "批次 28/70, 提取特征中...\n",
      "批次 29/70, 提取特征中...\n",
      "批次 30/70, 提取特征中...\n",
      "批次 31/70, 提取特征中...\n",
      "批次 32/70, 提取特征中...\n",
      "批次 33/70, 提取特征中...\n",
      "批次 34/70, 提取特征中...\n",
      "批次 35/70, 提取特征中...\n",
      "批次 36/70, 提取特征中...\n",
      "批次 37/70, 提取特征中...\n",
      "批次 38/70, 提取特征中...\n",
      "批次 39/70, 提取特征中...\n",
      "批次 40/70, 提取特征中...\n",
      "批次 41/70, 提取特征中...\n",
      "批次 42/70, 提取特征中...\n",
      "批次 43/70, 提取特征中...\n",
      "批次 44/70, 提取特征中...\n",
      "批次 45/70, 提取特征中...\n",
      "批次 46/70, 提取特征中...\n",
      "批次 47/70, 提取特征中...\n",
      "批次 48/70, 提取特征中...\n",
      "批次 49/70, 提取特征中...\n",
      "批次 50/70, 提取特征中...\n",
      "批次 51/70, 提取特征中...\n",
      "批次 52/70, 提取特征中...\n",
      "批次 53/70, 提取特征中...\n",
      "批次 54/70, 提取特征中...\n",
      "批次 55/70, 提取特征中...\n",
      "批次 56/70, 提取特征中...\n",
      "批次 57/70, 提取特征中...\n",
      "批次 58/70, 提取特征中...\n",
      "批次 59/70, 提取特征中...\n",
      "批次 60/70, 提取特征中...\n",
      "批次 61/70, 提取特征中...\n",
      "批次 62/70, 提取特征中...\n",
      "批次 63/70, 提取特征中...\n",
      "批次 64/70, 提取特征中...\n",
      "批次 65/70, 提取特征中...\n",
      "批次 66/70, 提取特征中...\n",
      "批次 67/70, 提取特征中...\n",
      "批次 68/70, 提取特征中...\n",
      "批次 69/70, 提取特征中...\n",
      "批次 70/70, 提取特征中...\n",
      "特征提取完成。\n"
     ]
    }
   ],
   "source": [
    "# 使用预训练的ResNet模型提取特征\n",
    "model = models.resnet18(pretrained=True)\n",
    "# 去掉模型的最后一层，用于分类任务的全连接层。\n",
    "# 保留了 ResNet-18 模型的特征提取部分\n",
    "model = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
    "\n",
    "# 提取特征\n",
    "features = []\n",
    "true_labels = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (images, labels) in enumerate(train_dataloader):\n",
    "        outputs = model(images)\n",
    "        features.extend(outputs.squeeze().numpy())\n",
    "        true_labels.extend(labels.numpy())\n",
    "\n",
    "        # 输出每个批次的进度\n",
    "        print(f'批次 {batch_idx + 1}/{len(train_dataloader)}, 提取特征中...')\n",
    "\n",
    "print(\"特征提取完成。\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 1.18205336e+00, -7.29721801e-01, -1.12696956e+00, ...,\n         7.32098361e-01, -5.25039198e-01, -6.22853315e-01],\n       [ 1.48848156e+00,  6.36829829e-01, -2.84690868e-01, ...,\n        -1.57586254e+00,  5.72960207e-01,  8.94853394e-01],\n       [ 1.33407889e+00,  1.80455261e-03, -3.19030747e-01, ...,\n        -4.09173442e-01, -6.78014844e-01,  2.56135942e-01],\n       ...,\n       [ 1.71640993e+00, -1.16847777e+00,  9.38286791e-01, ...,\n         3.96090773e-01, -5.96484077e-01, -8.47643643e-01],\n       [ 1.57049856e+00, -3.35172163e-01, -1.93209663e+00, ...,\n        -1.88350876e+00,  1.08855698e-02, -8.49626104e-01],\n       [-1.05756015e+00, -1.14169851e+00,  2.77216889e-01, ...,\n        -1.18589317e+00, -1.47108229e+00,  3.64303314e-01]])"
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 使用PCA降维\n",
    "n_components = 150\n",
    "pca = PCA(n_components=n_components, svd_solver='randomized', whiten=True).fit(features)\n",
    "features_pca = pca.transform(features)\n",
    "features_pca"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练SVM分类模型\n",
      "耗时 21.214s\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "# 训练SVM模型\n",
    "print(\"训练SVM分类模型\")\n",
    "t0 = time()\n",
    "param_grid = {'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "              'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1]}\n",
    "clf = GridSearchCV(SVC(kernel='rbf', class_weight='balanced'), param_grid)\n",
    "clf = clf.fit(features_pca, true_labels)\n",
    "print(\"耗时 %0.3fs\" % (time() - t0))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "网格搜索找到的最佳估计器:\n",
      "SVC(C=1000.0, class_weight='balanced', gamma=0.001)\n"
     ]
    }
   ],
   "source": [
    "print(\"网格搜索找到的最佳估计器:\")\n",
    "print(clf.best_estimator_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1,\n       0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n       0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n       1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n       0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n       1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n       0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n       1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n       0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n       1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n       0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n       1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n       1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1,\n       0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0,\n       1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n       0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1,\n       1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n       0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n       1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n       1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n       1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1,\n       0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n       0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n       0, 0, 0, 0, 0, 1, 0, 1, 0, 0], dtype=int64)"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在测试集上预测\n",
    "test_features = []\n",
    "test_true_labels = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_dataloader:\n",
    "        outputs = model(images)\n",
    "        test_features.extend(outputs.squeeze().numpy())\n",
    "        test_true_labels.extend(labels.numpy())\n",
    "\n",
    "# 使用PCA降维\n",
    "test_features_pca = pca.transform(test_features)\n",
    "# 在测试集上预测\n",
    "test_pred_labels = clf.predict(test_features_pca)\n",
    "test_pred_labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "1 0\n",
      "2 0\n",
      "3 1\n",
      "4 0\n",
      "5 1\n",
      "6 1\n",
      "7 1\n",
      "8 0\n",
      "9 0\n",
      "10 1\n",
      "11 1\n",
      "12 0\n",
      "13 0\n",
      "14 0\n",
      "15 0\n",
      "16 1\n",
      "17 0\n",
      "18 0\n",
      "19 1\n",
      "20 1\n",
      "21 0\n",
      "22 0\n",
      "23 0\n",
      "24 0\n",
      "25 1\n",
      "26 1\n",
      "27 1\n",
      "28 0\n",
      "29 0\n",
      "30 0\n",
      "31 1\n",
      "32 0\n",
      "33 0\n",
      "34 1\n",
      "35 1\n",
      "36 0\n",
      "37 0\n",
      "38 0\n",
      "39 0\n",
      "40 1\n",
      "41 1\n",
      "42 0\n",
      "43 0\n",
      "44 0\n",
      "45 1\n",
      "46 1\n",
      "47 0\n",
      "48 1\n",
      "49 1\n",
      "50 0\n",
      "51 1\n",
      "52 1\n",
      "53 0\n",
      "54 1\n",
      "55 0\n",
      "56 0\n",
      "57 0\n",
      "58 0\n",
      "59 0\n",
      "60 1\n",
      "61 0\n",
      "62 1\n",
      "63 1\n",
      "64 1\n",
      "65 1\n",
      "66 1\n",
      "67 1\n",
      "68 1\n",
      "69 1\n",
      "70 1\n",
      "71 0\n",
      "72 1\n",
      "73 1\n",
      "74 1\n",
      "75 0\n",
      "76 0\n",
      "77 1\n",
      "78 0\n",
      "79 0\n",
      "80 1\n",
      "81 0\n",
      "82 0\n",
      "83 0\n",
      "84 1\n",
      "85 1\n",
      "86 0\n",
      "87 1\n",
      "88 1\n",
      "89 0\n",
      "90 1\n",
      "91 1\n",
      "92 1\n",
      "93 0\n",
      "94 1\n",
      "95 1\n",
      "96 0\n",
      "97 1\n",
      "98 1\n",
      "99 0\n",
      "100 1\n",
      "101 0\n",
      "102 1\n",
      "103 0\n",
      "104 1\n",
      "105 1\n",
      "106 0\n",
      "107 1\n",
      "108 1\n",
      "109 1\n",
      "110 0\n",
      "111 0\n",
      "112 0\n",
      "113 0\n",
      "114 1\n",
      "115 1\n",
      "116 0\n",
      "117 1\n",
      "118 1\n",
      "119 1\n",
      "120 1\n",
      "121 1\n",
      "122 1\n",
      "123 1\n",
      "124 1\n",
      "125 0\n",
      "126 1\n",
      "127 0\n",
      "128 0\n",
      "129 1\n",
      "130 1\n",
      "131 1\n",
      "132 1\n",
      "133 0\n",
      "134 0\n",
      "135 1\n",
      "136 0\n",
      "137 0\n",
      "138 1\n",
      "139 1\n",
      "140 1\n",
      "141 0\n",
      "142 1\n",
      "143 1\n",
      "144 1\n",
      "145 0\n",
      "146 0\n",
      "147 0\n",
      "148 0\n",
      "149 1\n",
      "150 1\n",
      "151 1\n",
      "152 0\n",
      "153 1\n",
      "154 0\n",
      "155 0\n",
      "156 0\n",
      "157 0\n",
      "158 1\n",
      "159 1\n",
      "160 1\n",
      "161 0\n",
      "162 0\n",
      "163 1\n",
      "164 0\n",
      "165 0\n",
      "166 0\n",
      "167 1\n",
      "168 1\n",
      "169 1\n",
      "170 0\n",
      "171 0\n",
      "172 0\n",
      "173 0\n",
      "174 0\n",
      "175 1\n",
      "176 1\n",
      "177 0\n",
      "178 1\n",
      "179 1\n",
      "180 0\n",
      "181 1\n",
      "182 1\n",
      "183 1\n",
      "184 0\n",
      "185 0\n",
      "186 1\n",
      "187 0\n",
      "188 1\n",
      "189 0\n",
      "190 0\n",
      "191 0\n",
      "192 0\n",
      "193 1\n",
      "194 1\n",
      "195 1\n",
      "196 1\n",
      "197 0\n",
      "198 0\n",
      "199 1\n",
      "200 0\n",
      "201 1\n",
      "202 0\n",
      "203 0\n",
      "204 0\n",
      "205 1\n",
      "206 0\n",
      "207 0\n",
      "208 1\n",
      "209 1\n",
      "210 0\n",
      "211 0\n",
      "212 1\n",
      "213 1\n",
      "214 0\n",
      "215 1\n",
      "216 0\n",
      "217 0\n",
      "218 0\n",
      "219 1\n",
      "220 1\n",
      "221 0\n",
      "222 0\n",
      "223 0\n",
      "224 0\n",
      "225 0\n",
      "226 0\n",
      "227 0\n",
      "228 1\n",
      "229 0\n",
      "230 1\n",
      "231 1\n",
      "232 0\n",
      "233 0\n",
      "234 1\n",
      "235 0\n",
      "236 0\n",
      "237 0\n",
      "238 1\n",
      "239 1\n",
      "240 1\n",
      "241 0\n",
      "242 0\n",
      "243 0\n",
      "244 1\n",
      "245 1\n",
      "246 0\n",
      "247 1\n",
      "248 0\n",
      "249 1\n",
      "250 1\n",
      "251 1\n",
      "252 0\n",
      "253 0\n",
      "254 1\n",
      "255 0\n",
      "256 0\n",
      "257 0\n",
      "258 1\n",
      "259 0\n",
      "260 0\n",
      "261 1\n",
      "262 0\n",
      "263 1\n",
      "264 1\n",
      "265 0\n",
      "266 1\n",
      "267 1\n",
      "268 1\n",
      "269 1\n",
      "270 0\n",
      "271 1\n",
      "272 0\n",
      "273 1\n",
      "274 0\n",
      "275 1\n",
      "276 1\n",
      "277 0\n",
      "278 0\n",
      "279 1\n",
      "280 1\n",
      "281 1\n",
      "282 1\n",
      "283 1\n",
      "284 1\n",
      "285 0\n",
      "286 1\n",
      "287 0\n",
      "288 1\n",
      "289 0\n",
      "290 0\n",
      "291 0\n",
      "292 0\n",
      "293 1\n",
      "294 1\n",
      "295 0\n",
      "296 0\n",
      "297 1\n",
      "298 0\n",
      "299 1\n",
      "300 0\n",
      "301 1\n",
      "302 0\n",
      "303 0\n",
      "304 0\n",
      "305 1\n",
      "306 1\n",
      "307 1\n",
      "308 0\n",
      "309 0\n",
      "310 1\n",
      "311 1\n",
      "312 0\n",
      "313 0\n",
      "314 0\n",
      "315 1\n",
      "316 1\n",
      "317 1\n",
      "318 0\n",
      "319 1\n",
      "320 1\n",
      "321 0\n",
      "322 1\n",
      "323 1\n",
      "324 0\n",
      "325 1\n",
      "326 1\n",
      "327 1\n",
      "328 0\n",
      "329 0\n",
      "330 1\n",
      "331 0\n",
      "332 1\n",
      "333 0\n",
      "334 1\n",
      "335 1\n",
      "336 0\n",
      "337 1\n",
      "338 0\n",
      "339 1\n",
      "340 0\n",
      "341 1\n",
      "342 1\n",
      "343 0\n",
      "344 1\n",
      "345 1\n",
      "346 1\n",
      "347 0\n",
      "348 1\n",
      "349 1\n",
      "350 1\n",
      "351 1\n",
      "352 0\n",
      "353 0\n",
      "354 1\n",
      "355 1\n",
      "356 0\n",
      "357 1\n",
      "358 1\n",
      "359 0\n",
      "360 0\n",
      "361 0\n",
      "362 0\n",
      "363 1\n",
      "364 0\n",
      "365 1\n",
      "366 0\n",
      "367 0\n",
      "368 0\n",
      "369 1\n",
      "370 1\n",
      "371 0\n",
      "372 0\n",
      "373 1\n",
      "374 1\n",
      "375 1\n",
      "376 0\n",
      "377 0\n",
      "378 0\n",
      "379 1\n",
      "380 0\n",
      "381 1\n",
      "382 1\n",
      "383 0\n",
      "384 1\n",
      "385 1\n",
      "386 0\n",
      "387 1\n",
      "388 0\n",
      "389 1\n",
      "390 1\n",
      "391 1\n",
      "392 0\n",
      "393 0\n",
      "394 0\n",
      "395 0\n",
      "396 0\n",
      "397 1\n",
      "398 0\n",
      "399 0\n",
      "400 1\n",
      "401 1\n",
      "402 0\n",
      "403 0\n",
      "404 1\n",
      "405 1\n",
      "406 1\n",
      "407 0\n",
      "408 1\n",
      "409 0\n",
      "410 1\n",
      "411 0\n",
      "412 1\n",
      "413 0\n",
      "414 0\n",
      "415 1\n",
      "416 0\n",
      "417 0\n",
      "418 1\n",
      "419 0\n",
      "420 0\n",
      "421 1\n",
      "422 0\n",
      "423 0\n",
      "424 1\n",
      "425 1\n",
      "426 1\n",
      "427 1\n",
      "428 1\n",
      "429 1\n",
      "430 0\n",
      "431 1\n",
      "432 1\n",
      "433 0\n",
      "434 1\n",
      "435 0\n",
      "436 1\n",
      "437 0\n",
      "438 0\n",
      "439 0\n",
      "440 1\n",
      "441 0\n",
      "442 1\n",
      "443 1\n",
      "444 1\n",
      "445 1\n",
      "446 1\n",
      "447 0\n",
      "448 1\n",
      "449 1\n",
      "450 0\n",
      "451 1\n",
      "452 1\n",
      "453 0\n",
      "454 0\n",
      "455 0\n",
      "456 0\n",
      "457 0\n",
      "458 1\n",
      "459 0\n",
      "460 0\n",
      "461 0\n",
      "462 1\n",
      "463 0\n",
      "464 0\n",
      "465 1\n",
      "466 0\n",
      "467 0\n",
      "468 1\n",
      "469 0\n",
      "470 0\n",
      "471 0\n",
      "472 1\n",
      "473 0\n",
      "474 0\n",
      "475 0\n",
      "476 1\n",
      "477 0\n",
      "478 0\n",
      "479 0\n",
      "480 1\n",
      "481 1\n",
      "482 1\n",
      "483 1\n",
      "484 1\n",
      "485 1\n",
      "486 1\n",
      "487 0\n",
      "488 0\n",
      "489 0\n",
      "490 1\n",
      "491 0\n",
      "492 0\n",
      "493 0\n",
      "494 0\n",
      "495 1\n",
      "496 1\n",
      "497 0\n",
      "498 0\n",
      "499 1\n",
      "500 1\n",
      "501 1\n",
      "502 1\n",
      "503 1\n",
      "504 0\n",
      "505 1\n",
      "506 0\n",
      "507 1\n",
      "508 1\n",
      "509 1\n",
      "510 0\n",
      "511 0\n",
      "512 0\n",
      "513 1\n",
      "514 0\n",
      "515 0\n",
      "516 0\n",
      "517 1\n",
      "518 0\n",
      "519 0\n",
      "520 1\n",
      "521 1\n",
      "522 0\n",
      "523 0\n",
      "524 0\n",
      "525 0\n",
      "526 0\n",
      "527 1\n",
      "528 0\n",
      "529 0\n",
      "530 1\n",
      "531 1\n",
      "532 1\n",
      "533 0\n",
      "534 1\n",
      "535 1\n",
      "536 0\n",
      "537 1\n",
      "538 1\n",
      "539 0\n",
      "540 1\n",
      "541 1\n",
      "542 1\n",
      "543 1\n",
      "544 1\n",
      "545 1\n",
      "546 1\n",
      "547 1\n",
      "548 1\n",
      "549 1\n",
      "550 0\n",
      "551 0\n",
      "552 0\n",
      "553 0\n",
      "554 0\n",
      "555 1\n",
      "556 0\n",
      "557 1\n",
      "558 0\n",
      "559 0\n"
     ]
    },
    {
     "data": {
      "text/plain": "560"
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "true_labels_test = []\n",
    "for batch_idx, (images, labels) in enumerate(test_dataset):\n",
    "    print(i, labels)\n",
    "    true_labels_test.append(labels)\n",
    "    i += 1\n",
    "\n",
    "len(true_labels_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "560\n"
     ]
    },
    {
     "data": {
      "text/plain": "537"
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "array_test = np.array(true_labels_test - test_pred_labels)\n",
    "print(len(array_test))\n",
    "len(array_test) - np.count_nonzero(array_test)  # 长度减去非0的数就是0的数，0就是说真实和预测一样"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9589285714285715"
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_all = len(array_test)\n",
    "is_true = len(array_test) - np.count_nonzero(array_test)\n",
    "is_true / num_all"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分类报告：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         cat       0.96      0.96      0.96       277\n",
      "         dog       0.96      0.96      0.96       283\n",
      "\n",
      "    accuracy                           0.96       560\n",
      "   macro avg       0.96      0.96      0.96       560\n",
      "weighted avg       0.96      0.96      0.96       560\n",
      "\n",
      "混淆矩阵:\n",
      "[[266  11]\n",
      " [ 12 271]]\n"
     ]
    }
   ],
   "source": [
    "# 输出分类报告和混淆矩阵\n",
    "target_names = ['cat', 'dog']\n",
    "print(\"分类报告：\")\n",
    "print(classification_report(test_true_labels, test_pred_labels, target_names=target_names))\n",
    "print(\"混淆矩阵:\")\n",
    "print(confusion_matrix(test_true_labels, test_pred_labels))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 保存训练好的SVM模型\n",
    "# torch.save(clf, 'svm_model.pth') # 0.9642857142857143"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 保存PCA模型\n",
    "# torch.save(pca, 'pca_model.pth')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "新图像的预测类别是：dog\n"
     ]
    }
   ],
   "source": [
    "# 加载保存的SVM模型\n",
    "saved_model_path = './pth/svm_model.pth'\n",
    "clf = torch.load(saved_model_path)\n",
    "\n",
    "# 读取新图像\n",
    "new_image_path = r\"C:\\Users\\lenovo\\Downloads\\archive\\cat和dog\\test\\dog\\dog.1487.jpg\"\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "image = Image.open(new_image_path).convert(\"RGB\")\n",
    "image = transform(image).unsqueeze(0)\n",
    "\n",
    "# 提取特征\n",
    "model = models.resnet18(pretrained=True)\n",
    "model = torch.nn.Sequential(*(list(model.children())[:-1]))\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(image)\n",
    "\n",
    "features = outputs.squeeze().numpy()\n",
    "\n",
    "# 使用PCA降维\n",
    "features_pca = pca.transform(features.reshape(1, -1))\n",
    "\n",
    "# 预测\n",
    "predicted_label = clf.predict(features_pca)[0]\n",
    "\n",
    "# 映射预测标签到类别名称\n",
    "predicted_class = 'cat' if predicted_label == 0 else 'dog'\n",
    "\n",
    "print(f'新图像的预测类别是：{predicted_class}')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
